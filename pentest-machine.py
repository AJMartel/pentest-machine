#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import re
import sys
import time
import signal
import argparse
import requests
import subprocess
import concurrent.futures as cf
from urlparse import urlparse
from selenium import webdriver
from selenium.common.exceptions import WebDriverException
from subprocess import Popen, STDOUT, PIPE
from multiprocessing import Process, Pool, Manager, Queue
from requests_futures.sessions import FuturesSession
from libnmap.process import NmapProcess
from libnmap.parser import NmapParser, NmapParserException
requests.packages.urllib3.disable_warnings()
# Debug
#from IPython import embed

def parse_args():
    # Create the arguments
    parser = argparse.ArgumentParser()
    parser.add_argument("-x", "--nmapxml", help="Nmap XML file to parse")
    parser.add_argument("-l", "--hostlist", help="Host list file")
    parser.add_argument("-w", "--workers", type=int, default=10, help="Number of parallel workers")
    parser.add_argument("--no-brute", help="Skip all bruteforce attacks", action="store_true")
    parser.add_argument("-s", "--skip", help="Skip any command with this argument's string in it separated by commas, e.g: --skip dirb,nikto")
    return parser.parse_args()

def make_output_dirs():
    '''
    Create output directories
    '''
    dirs = ['output-by-host', 'output-by-service', 'output-by-cmd']
    for d in dirs:
        if not os.path.exists(d):
            os.makedirs(d)

def enqueue_cmds(queue, hosts, urls):
    '''
    Gather the commands to run
    '''

    hostnames = []
    hostname = None
    cmds = []
    cmd_strs = []

    for host in report.hosts:
        ip = host.address
        if host.is_up():
            # Each cmd = {service_str:[(cmd_string1, ip, service, bruteforce, slow_running)]}
            cmds += get_cmds_per_host(host, ip, urls, args)

    #Sort the commands so the fastest are at the front of the list
    # x[4] is boolean, True for slow running, False for fast running
    sorted_cmds = sorted(cmds, key=lambda x:x[4])

    for c in sorted_cmds:
        cmd_strs.append(c[0])
        queue.put(c)

    return cmd_strs

def get_cmds_per_host(host, ip, urls, args):
    '''
    For each service type, add commands to run against it
    '''
    # cmds = {service_str:[(cmd_string1, ip, service, bruteforce, slow_running)]}
    cmds = []

    for s in host.services:
        port = str(s.port)

        if 'open' in s.state and 'filtered' not in s.state:
            cmd_data_list = get_serv_cmds(s.service, ip, port, urls)
            if len(cmd_data_list) > 0:
                for c in cmd_data_list:
                    cmd_data = filter_cmds(c, port, args)
                    if cmd_data:
                        cmds.append(cmd_data)

    return cmds

def filter_cmds(cmd_data, port, args):
    '''
    Remove unnecessary commands
    '''
    cmd_str = cmd_data[0]

    # User-defined command skip
    if args.skip:
        # Split them at commas
        to_skip = args.skip.split(',')
        for c in to_skip:
            if c in cmd_str:
                return

    # Skip brute force if necessary
    if args.no_brute == True:
        if cmd_data[3] == True:
            return

    # RPC
    # only do showmount if it's an NFS port
    if '/sbin/showmount' in cmd_str:
        if port not in ['111', '2049']:
            return

    return cmd_data

def get_serv_cmds(service, ip, port, urls):
    '''
    List of cmds to run on a per-service basis
    serv_cmds = {service_str:[(cmd_string, ip, service, bruteforce, slow_running)]}
    '''

    cmds = []
    ip_port = '{0}:{1}'.format(ip, port)

    serv_cmds = {'ftp':[('submodules/patator/patator.py ftp_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
--max-retries 3 port={1}'.format(ip, port), ip_port, 'FTP', True, True)],

                 # Eventually add bruteforce against SMTP by first doing smtp_vrfy brute then using those SNs to attack
                 'smtp':[('/usr/bin/nmap -sSV -Pn -n -pT{0} --script smtp-enum-users,smtp-open-relay {1}'.format(port, ip), ip_port, 'SMTP', True, True)],

                 'postgre':[('submodules/patator/patator.py postgresql_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
--max-retries 3'.format(ip), ip_port, 'Postgres', True, True)],

                 'mysql':[('submodules/patator/patator.py mysql_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
--max-retries 3'.format(ip), ip_port, 'MYSQL', True, True)],

                 'ms-sql':[('submodules/patator/patator.py mssql_login host={0} port={1} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
--max-retries 3'.format(ip, port), ip_port, 'MSSQL', True, True)],

                 #  Argh why don't you work, throws k,v unpacking exceptions
#                 'telnet':[('python submodules/patator/patator.py telnet_login host={0} inputs="COMBO00\nCOMBO01" 0=wordlists/short-user-pass.list \
#reset:fgrep!="Login incorrect", --max-retries 3'.format(ip), ip_port, 'Telnet', True, True)],

                 'ssh':[('submodules/patator/patator.py ssh_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
port={1} --max-retries 2'.format(ip, port), ip_port, 'SSH', True, True)],

                 'snmp':[('submodules/patator/patator.py snmp_login host={0} community=FILE0 0=wordlists/112-snmp.list'.format(ip), ip_port, 'SNMP', True, False)],

                 'rpc':[('/sbin/showmount -e {0}'.format(ip), ip_port, 'RPC', False, False)],

                 'smb|microsoft-ds':[('submodules/enum4linux/enum4linux.pl -a {0}'.format(ip), ip_port, 'SMB', False, False)],

                                                                                   # These are the only two rdp scripts
                 'ms-wbt-server':[('/usr/bin/nmap -sSV -Pn -n -p{0} --script rdp-enum-encryption,rdp-vuln-ms12-020 {1}'.format(port, ip), ip_port, 'RDP', False, False)],

                 'ntp':[('/usr/bin/nmap -sUV -Pn -n -p{0} --script ntp-monlist {1}'.format(port, ip), ip_port, 'NTP', False, False)],

                 'sip':[('/usr/bin/nmap -sSV -Pn -n -p{0} --script sip-enum-users,sip-methods {1}'.format(port, ip), ip_port, 'SIP', False, False),
                        ('submodules/sipvicious/sipvicious/svmap.py -p{0} {1}'.format(port, ip), ip_port, 'SIP', False, False)],

                 'dns':[('/usr/bin/nmap -sUV -Pn -n -p{0} --script dns-zone-transfer,dns-recursion {1}'.format(port, ip), ip_port, 'DNS', False, False)],

                 'http|www|ssl':http_cmds}

    for serv in serv_cmds:
        # If the service string in s.service
        if re.search(serv, service):
            if 'http|www|ssl' == serv:
                cmds += serv_cmds[serv](ip_port, urls)
            else:
                cmds += serv_cmds[serv]

    return cmds

def http_cmds(ip_port, urls):
    '''
    Form all the commands to run against HTTP services
    and add them to the Queue
    Runs: nikto, whatweb, screenshooter(), dirb
    '''
    cmds = []
    split = ip_port.split(':')
    ip = split[0]
    port = split[1]

    for url in urls:

        if ip_port in url:

            # WhatWeb
            whatweb = 'submodules/WhatWeb/whatweb {0} 2>/dev/null'.format(url)
            cmds.append((whatweb, ip_port, 'HTTP', False, False))

            # Directory bruteforcing
            dirb = 'dirb {0} {1}'.format(url, 'wordlists/dirs-1800.list')
            cmds.append((dirb, ip_port, 'HTTP', True, True))

    return cmds

def get_urls(report):
    '''
    Create, then asynchronously test all the valid URLs based on http/https and ip/hostname
    '''

    # Create all potential URLs from the IP and hostname
    potential_urls = get_potential_urls(report)

    # Start asynchronous requests to the potential URLs
    resps = resps_from_urls(potential_urls)

    # Get the results from the requests to the potential URLs
    working_urls = get_working_urls(resps)

    return working_urls

def get_working_urls(resps):
    '''
    Test each potential URL for a valid resp
    '''
    working_urls = []
    print '\n[*] Asynchronously gathering valid URLs...'
    for resp in cf.as_completed(resps):
        try:
            url = resp.result().url
            if resp.result().status_code != 404:
                if url not in working_urls:
                    working_urls.append(url)
        except Exception as e:
            # Uncomment to see reason for failure, but not URL (SSL errors prevent rep.result().url)
            #print '[-]   {}'.format(str(e))
            continue

    # Eliminate URL paths so it's just the host and port, can have a path if it redirects
    working_urls = clean_working_urls(working_urls)

    print ''
    return working_urls

def clean_working_urls(working_urls):
    '''
    If the URL redirects with a path, we need to eliminate the path
    '''
    rm_path_urls = []
    for u in working_urls:
        parsed = urlparse(u)
        new_url = parsed.scheme+'://'+parsed.netloc
        if new_url not in rm_path_urls:
            print '[+]   {}'.format(new_url)
            rm_path_urls.append(new_url)

    return rm_path_urls

def get_potential_urls(report):
    '''
    Print all the hosts and services per host
    Create all potential URL combinations from the nmap IP/hostname
    '''
    potential_urls = []

    for host in report.hosts:
        ip = host.address
        if host.is_up():
            print '\n[+] Host: {0}'.format(ip)
            for s in host.services:
                port = str(s.port)
                print '[*]   {0}/{1} {2} {3}'.format(port, s.protocol, s.state, s.service)
                ip_port = '{0}:{1}'.format(ip, port)
                # Set protocol to http:// by default and adjust to https:// when
                # 'https' or 'ssl' in service name
                if re.search('http|www|ssl', s.service):
                    protocol = 'http://'
                    # Check for https and ssl so we can change the protocol
                    if re.search('https|ssl', s.service) or port == '443':
                        protocol = 'https://'
                    url = '{0}{1}'.format(protocol, ip_port)
                    potential_urls.append(url)

    return potential_urls

def resps_from_urls(potential_urls):
    '''
    Gather valid responses from the list of potential urls
    '''
    resps = []
    session = FuturesSession(max_workers=30)
    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0'}

    for url in potential_urls:
        resp = session.get(url, timeout=25, verify=False, headers=headers)
        resps.append(resp)

    return resps

def screenshooter(ip, url):
    '''
    Open a phantomjs browser and take a screenshot
    '''

    output = ''

    try:
        browser = webdriver.PhantomJS(service_args=['--ignore-ssl-errors=true','--ssl-protocol=tlsv1'], executable_path="phantomjs")
    except WebDriverException:
        output += '[-] PhantomJS failed, are you sure its installed and in your $PATH?\n'
        return output

    output += '[*] Taking screenshot of {0}\n'.format(url)
    ss_name = url.split('://')[1].replace(':', '-').strip('/')
    browser.set_window_size(1024, 768)
    browser.set_page_load_timeout(60)

    try:
        browser.get(url)

        # Selenium makes the page source equal to this when it fails to connect
        if '<html><head></head><body></body></html>' == browser.page_source:
            output += '[-] Failed to fetch the page\n'
            return output

        fname = 'output-by-service/Screenshots/{0}.png'.format(ss_name)
        fname2 = 'output-by-cmd/Screenshots/{0}.png'.format(ss_name)
        browser.save_screenshot(fname)
        browser.save_screenshot(fname2)
    except Exception as e:
        output += '[-] Failed: {0}\n'.format(str(e))
        return output

    output += '[+] Saved screenshot {0}.png'.format(ss_name)
    browser.quit()

    return output

def worker(lock, queue, proc_monitor):
    '''
    Multiprocessing worker that actually runs the commands
    '''
    signal.signal(signal.SIGINT, signal.SIG_IGN)
    pid = os.getpid()

    #while queue.qsize() > 0:
    while 1:
        waiting_for_item = True

        # Necessary to catching CTRL-C
        try:
            # This has to wait for write_output() and causes IOError sometimes on CTRL-C
            proc_monitor[pid] = waiting_for_item
            # This causes EOFError on CTRL-C
            cmd_data = queue.get()
        except (EOFError, IOError):
            return

        # Tells the shared dict proc_monitor that we are performing actions
        # based on a queue object so don't finish the script yet
        proc_monitor[pid] = False
        cmd = cmd_data[0]
        cmd_list = cmd.split()
        ip_port = cmd_data[1]
        split = ip_port.split(':')
        ip = split[0]
        port = split[1]
        service = cmd_data[2]

        out = run_cmd(cmd_list, cmd, ip)
        out = adjust_output(cmd_list, out)

        # On Ctrl-C will throw IOError if it came while writing
        try:
            if out:
                write_output(lock, cmd, ip, service, out)
        except IOError:
            return

        # Add new cmds
        add_new_cmds(queue, cmd_list, ip_port, out)

def run_cmd(cmd_list, cmd, ip):
    '''
    Run either the OS command or call a function based on cmd_data
    '''
    out = None

    print '[*] Running command: {0}'.format(cmd)
    proc = Popen(cmd_list, stdout=PIPE, stderr=STDOUT)
    out = proc.communicate()[0].strip()

    return out

def write_output(lock, full_cmd, ip, service, out):
    '''
    Write each cmd's output to a file named by the IP and a file named by the service type
    '''
    split_cmd = full_cmd.split()

    # Narrow down the full cmd to just the base program name
    cmd = split_cmd[0]
    # For when it's like /usr/bin/nmap
    if '/' in cmd:
        cmd = cmd.split('/')[-1]

    with lock:
        msg = '\n[+] OUTPUT: {0}\n{1}'.format(full_cmd, out)
        print msg

        with open('output-by-host/{0}.txt'.format(ip), 'a+') as f:
            f.write(msg)
        with open('output-by-service/{0}.txt'.format(service), 'a+') as f:
            f.write(msg)
        with open('output-by-cmd/{0}.txt'.format(cmd), 'a+') as f:
            f.write(msg)

def adjust_output(cmd_list, out):
    '''
    Remove output from cmds with too much of it and remove errors from some cmds' output
    '''
    # Skip certain output lines
    adjusted_out = ''
    for l in out.split('\n'):

        # Skip dirb crap
        if '/usr/bin/dirb' in cmd_list:
            # Make sure the line has at least some findings
            if ' (CODE:' in l or '==> DIRECTORY' in l:
                parts = l.split('\r')
                for p in parts:
                    line = p.strip()
                    if len(line) > 0 and '--> Testing:' not in line and 'Calculating NOT_FOUND' not in line:
                        adjusted_out += line + '\n'
            else:
                continue

        # Skip error line in whatweb
        elif 'iconv will be deprecated in the future' not in l:
            adjusted_out += l + '\n'

    # Escape colors like whatweb has
    ansi_escape = re.compile(r'\x1b[^m]*m')
    out = ansi_escape.sub('', adjusted_out)

    return out

def nmap_scan(hosts):
    '''
    Do Nmap scan
    '''
    # -sV is included by default in NmapProcess nmap cmd
    # To add more:  options = '-T4 -sU -p-'
    #                 hosts = ['192.168.0.1', '192.168.0.2']
    #nmap_args = '-T4 -sV -sS -pU:161,137,139'# -sS -sU --top-ports'
    nmap_args = '-T4 -sS -sV --max-rtt-timeout 100ms --max-retries 3'
    print '[*] Running: nmap {0} -iL <hostlist>'.format(nmap_args)
    nmap_proc = NmapProcess(targets=hosts, options=nmap_args)
    #rc = nmap_proc.sudo_run()
    rc = nmap_proc.sudo_run_background()
    while nmap_proc.is_running():
        print("[*] Nmap progress: {1}%".format(nmap_proc.etc, nmap_proc.progress))
        time.sleep(2)

    xml = nmap_proc.stdout

    try:
        report = NmapParser.parse(nmap_proc.stdout)
    except NmapParserException as e:
        print 'Exception raised while parsing scan: {0}'.format(e.msg)
        sys.exit()

    return report

############################# ADD NEW CMDS #####################################################
def add_new_cmds(queue, cmd_list, ip_port, out):
    '''
    Based the output of one of the originally run cmds, add new cmds
    to the queue for the workers to process
    '''
    new_cmds = {'/usr/bin/whatweb':add_wpscan,
               'snmp_login':add_snmpcheck}

    for cmd_snippet in new_cmds:
        if cmd_snippet in cmd_list:
            new_cmds[cmd_snippet](out, ip_port, queue, cmd_list)

def add_snmpcheck(out, ip_port, queue, cmd_list):
    '''
    Add snmpcheck to gather info from valid SNMP logins
    '''
    split = ip_port.split(':')
    ip = split[0]

    if 'snmp_login' in cmd_list:
        out_lines = out.splitlines()
        for l in out_lines:
            # 0-0 is the code and is only found on lines of output referring to a brute attempt
            if '0-0' in l:
                if 'No SNMP response received' not in l:
                    split_line = l.split()
                    comm_str = split_line[7]
                    snmpcheck = 'snmp-check {0} -c {1} -w'.format(ip, comm_str)
                    queue.put((snmpcheck, ip_port, 'SNMP', False, False))

def add_wpscan(out, ip_port, queue, cmd_list):
    '''
    Add WPScan to queue if "wordpress" is in whatweb output
    '''
    if 'wordpress' in out.lower():
        url = cmd_list[1]
        wp = '/usr/bin/wpscan {0}'.format(url)
        cmd = (wp, ip_port, 'HTTP', False, False)
        queue.put(cmd)
        return
################################################################################################

def kill_procs(c):
    ps = subprocess.Popen(('ps', 'aux'), stdout=subprocess.PIPE)
    ps_out = ps.communicate()[0].splitlines()
    for l in ps_out:
        if 'grep ' not in l:
            if c in l:
                os.kill(int(l.split()[1]), signal.SIGKILL)

def main(report, num_workers):
    '''
    Run through the hosts' available services appending their respective commands
    to a list, then have x number of workers run through those commands
    '''
    args = parse_args()
    # Can't just use multiprocessing.Lock() because you can't share locks between pool-created Processes
    m = Manager()
    lock = m.Lock()
    proc_monitor = m.dict()
    # Regular Queue() gets pickled and unpickled by each worker which means its copied so it can't be shareed between Procs
    queue = m.Queue()

    # Create output directories
    make_output_dirs()

    # Check web services for valid URLs
    urls = get_urls(report)

    # Enqueue all the cmds based on the services detected
    cmd_strs = enqueue_cmds(queue, report.hosts, urls)

    # Kick off the workers in the Pool
    pool = Pool(num_workers, worker, (lock, queue, proc_monitor))

    # Every second check if all the processes are waiting on the queue which would
    # mean all cmds are done and all are just infinitely waiting for a new task
    while 1:
        try:
            time.sleep(1)

            procs_waiting = []
            # Can't iterate over DictProxy with `for key in DictProxy`
            # which is what Manager().dict() is so gotta do this
            pids = iter(proc_monitor.keys())
            for p in pids:
                procs_waiting.append(proc_monitor[p])

            # If all procs are just waiting, then we're done
            if all(procs_waiting):
                pool.terminate()
                pool.join()
                if os.path.isfile('ghostdriver.log'):
                    os.remove('ghostdriver.log')
                return
        except KeyboardInterrupt:
            print '\n[-] Killing unfinished processes...'
            if os.path.isfile('ghostdriver.log'):
                os.remove('ghostdriver.log')
            pool.terminate()
            pool.join()
            # Kill remaining processes, {{}} values are ignored by .format()
            # Append the phantomjs cmd that gets called from selenium
            cmd_strs.append('phantomjs --ignore-ssl-errors=true --ssl-protocol=tlsv1 --webdriver=')
            for c in cmd_strs:
                kill_procs(c)
            sys.exit()


if __name__ == "__main__":

    args = parse_args()

    if os.geteuid():
        exit('[-] Please run as root')

    if args.nmapxml:
        report = NmapParser.parse_fromfile(args.nmapxml)
    elif args.hostlist:
        with open(args.hostlist, 'r') as hostlist:
            hosts = hostlist.read().split()
        report = nmap_scan(hosts)
    else:
        print 'Please use the "-x [nmapoutput.xml]" option if you already have an nmap XML file \
or "-l [hostlist.txt]" option to run an nmap scan with a hostlist file.'
        sys.exit()

    main(report, args.workers)
