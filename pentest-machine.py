#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import re
import sys
import time
import signal
import argparse
import requests
import subprocess
import concurrent.futures as cf
from selenium import webdriver
from subprocess import Popen, STDOUT, PIPE
from multiprocessing import Lock, Process, Queue
from requests_futures.sessions import FuturesSession
from libnmap.process import NmapProcess
from libnmap.parser import NmapParser, NmapParserException
requests.packages.urllib3.disable_warnings()
# Debug
#from IPython import embed

def parse_args():
    # Create the arguments
    parser = argparse.ArgumentParser()
    parser.add_argument("-x", "--nmapxml", help="Nmap XML file to parse")
    parser.add_argument("-l", "--hostlist", help="Host list file")
    parser.add_argument("-w", "--workers", type=int, default=10, help="Number of parallel workers")
    parser.add_argument("--no-brute", help="SKip all bruteforce attacks", action="store_true")
    return parser.parse_args()

def main(report, num_workers):
    '''
    Run through the hosts' available services appending their respective commands
    to a list, then have x number of workers run through those commands
    '''
    procs = []
    lock = Lock()
    q = Queue()

    # Catch CTRL-C
    def signal_handler(signal, frame):
        # Stop further processes from spawning
        q.put('STOP')
        print '[-] Killing process'
        for p in procs:
            p.terminate()
        q.close()
    signal.signal(signal.SIGINT, signal_handler)

    # Create output directories
    if not os.path.exists('output-by-host'):
        os.makedirs('output-by-host')
    if not os.path.exists('output-by-service'):
        os.makedirs('output-by-service')

    # Check web services for valid URLs
    urls = get_urls(report)
    print ''

    # Run cmds based on the service
    hostname = None
    for host in report.hosts:
        ip = host.address
        if host.is_up():
            # type(host.hostnames) == list
            if len(host.hostnames) != 0:
                hostname = host.hostnames[0]
            # Add the various cmds and filenames to the queue
            do_service_cmds(host, hostname, ip, q, urls)

    # Go through the queue with x number of workers
    for w in xrange(num_workers):
        p = Process(target=worker, args=(q, lock))
        p.start()
        procs.append(p)
        q.put('STOP')

    for p in procs:
        p.join()

def do_service_cmds(host, hostname, ip, q, urls):
    '''
    For each service type, add a command to run against it to the queue

      To do:
      DNS
        maybe dns amplification?
      IKE
       ike-scan
      Postgresql
        brute/blank login
      DHCP
        ?
      LDAP
        brute
    '''
    if len(host.services) == 0:
        print '[-] No services detected'

    for s in host.services:
        #if 'open' in s.state or 'filtered' in s.state:
        port = str(s.port)

        serv_to_func = {'http|www|ssl':http_cmds,
                         'smtp':smtp_cmds,
                         'smb':smb_cmds,
                         'rpc':rpc_cmds,
                         'snmp':snmp_cmds,
                         'ftp':ftp_cmds,
                         'ssh':ssh_cmds,
                         'mssql':mssql_cmds,
                         'mysql':mysql_cmds,
                         'postgre':postgresql_cmds,
                         'telnet':telnet_cmds}

        for serv in serv_to_func:
            if re.search(serv, s.service):
                # HTTP testing requires a couple extra vars
                if serv == 'http|www|ssl':
                    serv_to_func[serv](q, ip, port, hostname, s.service, urls)
                # All the rest of the protocol testing
                else:
                    serv_to_func[serv](q, ip, port)

def get_urls(report):
    '''
    Asynchronously get all the valid URLs for testing
    '''
    session = FuturesSession(max_workers=25)
    urls = {}
    untested_urls = {}
    resps = {}

    for host in report.hosts:
        ip = host.address
        if host.is_up():
            hostname = None
            if len(host.hostnames) != 0:
                hostname = host.hostnames[0]
                print '\n[*] Host: {0}  Hostname: {1}'.format(ip, hostname)
            else:
                print '\n[+] Host: {0}'.format(ip)
            for s in host.services:
                port = str(s.port)
                print '[*]   {0}/{1} {2} {3} {4}'.format(port, s.protocol, s.state, s.service, s.servicefp)
                ip_port = '{0}:{1}'.format(ip, port)
                if re.search('http|www|ssl', s.service):
                    # Create the potential URLs
                    host_urls = make_urls(ip, port, hostname)
                    if host_urls:
                        untested_urls[ip_port] = host_urls

    # Start asynchronous requests to the potential URLs
    for ip_port in untested_urls:
        host_resps = []
        for url in untested_urls[ip_port]:
            resp = session.get(url, timeout=25, verify=False)
            host_resps.append(resp)
            resps[resp] = (url, ip_port)

    # Get the results from the requests to the potential URLs
    print '\n[*] Asynchronously gathering valid URLs...'
    for resp in cf.as_completed(resps):
        try:
            if resp.result().status_code in [200, 401]:
                url, ip_port = resps[resp]
                print '[+]   Successful response: {0}'.format(url)
                if ip_port in urls:
                    urls[ip_port] += [url]
                else:
                    urls[ip_port] = [url]
        except Exception as e:
            pass

    return urls

def postgresql_cmds(q, ip, port):
    no_brute = parse_args().no_brute
    if not no_brute:
        # Brute force
        postgresql_login = 'patator postgresql_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
--max-retries -2'.format(ip)
        q.put((postgresql_login.split(), ip, 'POSTGRESQL', False))

def mysql_cmds(q, ip, port):
    no_brute = parse_args().no_brute
    if not no_brute:
        # Brute force
        mysql_login = 'patator mysql_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
--max-retries -2'.format(ip)
        q.put((mysql_login.split(), ip, 'MYSQL', False))

def mssql_cmds(q, ip, port):
    no_brute = parse_args().no_brute
    if not no_brute:
        # Brute force (never more than 2 tries per username to avoid lockout
        # -x free=user:code0 means stop testing the user after successful login
        mssql_login = 'patator mssql_login host={0} user=sa password=FILE0 0=wordlists/top26pw.list \
--max-retries -2'.format(ip)
        q.put((mssql_login.split(), ip, 'MSSQL', False))

def telnet_cmds(q, ip, port):
    '''
    Runs: patator telnet_login
    '''
    # Brute force
    telnet = 'patator telnet_login host={0} inputs="COMBO00\nCOMBO01" 0=wordlists/short-user-pass.list \
--max-retries -2'.format(ip)
    telnet_split = telnet.split()
    q.put((telnet_split, ip, 'Telnet', False))

def ssh_cmds(q, ip, port):
    '''
    Runs: patator ssh_login
    '''
    no_brute = parse_args().no_brute
    if not no_brute:
        # Brute force (never more than 2 tries per username to avoid lockout
        # -x free=user:code0 means stop testing the user after successful login
        ssh_login = 'patator ssh_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
    -x ignore:egrep="failed." -x free=user:code=0 port={1} --max-retries -2'.format(ip, port)
        ssh_login_split = ssh_login.split()
        q.put((ssh_login_split, ip, 'SSH', False))

def ftp_cmds(q, ip, port):
    '''
    Runs: patator ftp_login, anon login
    '''
    no_brute = parse_args().no_brute
    if not no_brute:
        # Brute force (never more than 2 tries per username to avoid lockout except root and admin)
        ftp_login = 'patator ftp_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
-x ignore:egrep="failed" -x free=user:code=0 port={1} --max-retries -2'.format(ip, port)
        ftp_login_split = ftp_login.split()
        q.put((ftp_login_split, ip, 'FTP', False))

def snmp_cmds(q, ip, port):
    '''
    Runs: snmpcheck with 'public' and 'private' strings
    '''
    snmpcheck = '/usr/bin/snmpcheck -t {0}'.format(ip)
    snmpcheck_split = snmpcheck.split()
    q.put((snmpcheck_split, ip, 'SNMP', False))

    snmpcheck1 = '/usr/bin/snmpcheck -t {0} -c "private"'.format(ip)
    snmpcheck1_split = snmp_check1.split()
    q.put((snmpcheck1_split, ip, 'SNMP', False))

def rpc_cmds(q, ip, port):
    '''
    Runs: showmount
    '''
    # NFS runs on port 111, 2049 TCP/UDP for btoh
    ports = ['111', '2049']
    if port in ports:
        showmount = 'sudo /sbin/showmount -e {0}'.format(ip)
        showmount_split = showmount.split()
        q.put((showmount_split, ip, 'RPC', False))

def http_cmds(q, ip, port, hostname, service, urls):
    '''
    Form all the commands to run against HTTP services
    and add them to the Queue
    Runs: nikto, whatweb, screenshooter(), dirb
    '''

    for ip_port in urls:
        # Check if the ip_port matches this single hosts's ip and port
        if ip_port == '{0}:{1}'.format(ip, port):
            for url in urls[ip_port]:
                # Nikto
                nikto = '/usr/bin/nikto -h {0}'.format(url)
                q.put((nikto.split(), ip, 'HTTP', False))

                # WhatWeb
                whatweb = '/usr/bin/whatweb {0}'.format(url)
                q.put((whatweb.split(), ip, 'HTTP', False))

                # HTTP screenshots
                if not os.path.exists('output-by-service/HTTP-screenshots'):
                    os.makedirs('output-by-service/HTTP-screenshots')
                ss = 'screenshooter {0}'.format(url)
                q.put((ss.split(), ip, 'HTTP', True))

                # Directory bruteforcing
                no_brute = parse_args().no_brute
                if not no_brute:
                    dirb = 'dirb -o output-by-service/HTTP-dirb.txt {0} {1}'.format(url, 'wordlists/dirs-files-6000.list')
                    q.put((dirb.split(), ip, 'HTTP', False))
                    # Wfuzz's output is all unreadable by this script unfortunately
                    #wfuzz = 'wfuzz -z file,wordlists/dirs-files-6000.list --hc 404 -I --follow {0}/FUZZ'.format(url)
                    #q.put((wfuzz.split(), ip, 'HTTP', False))

   ###### Gotta figure out how to save the report right ###############
        # Runs Arachni with high risk checks for 45 min max
#        ua = "Mozilla/6.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) \
#Chrome/37.0.2062.124 Safari/537.36"
#        if hostname:
#            path = os.getcwd() + '/output-by-host/arachni-report-{0}-{1}.txt'.format(hostname, port)
#            arachni = 'sudo arachni --output-only-positives --audit-links --audit-forms --http-user-agent \
#--checks=sql*,file_inclusion,path_traversal,xpath_injection,os_cmd_injection \
#--browser-cluster-ignore-images --report-save-path={1} --timeout=0:45:0 "{2}://{3}"'.format(port, path, scheme, hostname)
#        else:
#            path = os.getcwd() + '/output-by-host/arachni-report-{0}-{1}.txt'.format(ip, port)
#            arachni = 'sudo arachni --output-only-positives --audit-links --audit-forms --http-user-agent \
#--checks=sql*,file_inclusion,path_traversal,xpath_injection,os_cmd_injection \
#--browser-cluster-ignore-images --report-save-path={1} --timeout=0:45:0 "{2}://{3}"'.format(port, path, scheme, ip)
#        arachni_split = arachni.split()
#        # Insert the UA which has spaces in it but can't be split up
#        # when cmd.split() is called by worker()
#        arachni_split.insert(6, ua)
#        q.put((arachni_split, ip, 'HTTP'))

def screenshooter(ip, url):
    '''
    Open a phantomjs browser and take a screenshot
    '''

    output = ''

    try:
        browser = webdriver.PhantomJS(service_args=['--ignore-ssl-errors=true','--ssl-protocol=tlsv1'], executable_path="phantomjs")
    except WebDriverException:
        output += '[-] PhantomJS failed, are you sure its installed and in your $PATH?\n'
        return output

    output += '[*] Taking screenshot of {0}\n'.format(url)
    ss_name = url.split('://')[1].replace(':', '-')
    browser.set_window_size(1024, 768)
    browser.set_page_load_timeout(60)

    try:
        browser.get(url)

        # Selenium makes the page source equal to this when it fails to connect
        if '<html><head></head><body></body></html>' == browser.page_source:
            output += '[-] Failed to fetch the page\n'
            return output

        fname = 'output-by-service/HTTP-screenshots/{0}.png'.format(ss_name)
        browser.save_screenshot(fname)
    except Exception as e:
        output += '[-] Failed: {0}\n'.format(str(e))
        return output

    output += '[+] Saved screenshot {0}.png\n'.format(ss_name)
    browser.quit()

    return output

def make_urls(ip, port, hostname):
    '''
    Create all potential URLs, http://hostname, http://ip, https://hostname, https://ip
    '''
    urls = []

    if port == '443':
        if hostname:
            urls.append('https://{0}:{1}'.format(hostname, port))
        urls.append('https://{0}:{1}'.format(ip, port))
        return urls
    else:
        if hostname:
            urls.append('http://{0}:{1}'.format(hostname, port))
            urls.append('https://{0}:{1}'.format(hostname, port))
        urls.append('http://{0}:{1}'.format(ip, port))
        urls.append('https://{0}:{1}'.format(ip, port))
        return urls

def smtp_cmds(q, ip, port):
    '''
    Runs: Nmap NSE smtp-enum-users,smtp-open-relay
    '''
    nmap_smtp = '/usr/bin/nmap -Pn -n -p {0} --script smtp-enum-users,smtp-open-relay {1}'.format(port, ip)
    nmap_smtp_split = nmap_smtp.split()
    q.put((nmap_smtp.split(), ip, 'SMTP', False))

def smb_cmds(q, ip, port):
    '''
    Runs: enum4linux -a
          nmap NSE smb-check-vulns, smb-enum-shares
    '''
    enum4linux = '/usr/bin/enum4linux -a {0}'.format(ip)
    enum4linux_split = enum4linux.split()
    q.put((enum4linux_split, ip, 'SMB', False))

    nmap_smb = '/usr/bin/nmap -Pn -n -p {0} --script smb-check-vulns,smb-enum-shares {1}'.format(port, ip)
    nmap_smb_split = nmap_smb.split()
    q.put((nmap_smb_split, ip, 'SMB', False))

def worker(q, lock):
    '''
    Multiprocessing worker that actually runs the commands
    '''
    skip_output = ['arachni', 'dirb']

    for cmd_list, ip, serv, built_in in iter(q.get, 'STOP'):

        cmd = ' '.join(cmd_list)

        # Run python functions, come in as "<functionname> <args>"
        if built_in == True:
            if 'screenshooter' in cmd:
                print '[*] Running command: {0}'.format(cmd)
                url = cmd.split()[1]
                out = screenshooter(ip, url)

        # Run OS cmds
        else:
            print '[*] Running command: {0}'.format(cmd)

            proc = Popen(cmd_list, stdout=PIPE, stderr=STDOUT)
            out = proc.communicate()[0].strip()

        # Ignore cmds with too much or unprintable output
        for i in skip_output:
            if i == cmd_list[0]:
                return

        # Skip certain output lines
        new_out = ''
        for l in out.split('\n'):
            # Skip error line in whatweb
            if 'iconv will be deprecated in the future' not in l:
                new_out += l + '\n'
        out = new_out

        # Escape colors like whatweb has
        ansi_escape = re.compile(r'\x1b[^m]*m')
        out = ansi_escape.sub('', out)

        msg = '\n[+] OUTPUT: {0}\n{1}'.format(cmd, out)
        print msg

        with lock:
            with open('output-by-host/{0}.txt'.format(ip), 'a+') as f:
                f.write(msg)
            with open('output-by-service/{0}.txt'.format(serv), 'a+') as f:
                f.write(msg)

def nmap_scan(hosts):
    '''
    Do Nmap scan
    '''
    # -sV is included by default in NmapProcess nmap cmd
    # To add more:  options = '-T4 -sU -p-'
    #                 hosts = ['192.168.0.1', '192.168.0.2']
    #nmap_args = '-T4 -sV -sS -pU:161,137,139'# -sS -sU --top-ports'
    nmap_args = '-T4 -sS -sV --max-rtt-timeout 150ms --max-retries 3'
    print '[*] Running: nmap {0} -iL <hostlist>'.format(nmap_args)
    nmap_proc = NmapProcess(targets=hosts, options=nmap_args)
    #rc = nmap_proc.sudo_run()
    rc = nmap_proc.sudo_run_background()
    while nmap_proc.is_running():
        print("[*] Nmap progress: {1}%".format(nmap_proc.etc,
                                                              nmap_proc.progress))
        time.sleep(2)

    xml = nmap_proc.stdout

    try:
        report = NmapParser.parse(nmap_proc.stdout)
    except NmapParserException as e:
        print 'Exception raised while parsing scan: {0}'.format(e.msg)
        sys.exit()

    return report


if __name__ == "__main__":

    if os.geteuid():
        exit('[-] Please run as root')

    args = parse_args()

    if args.nmapxml:
        report = NmapParser.parse_fromfile(args.nmapxml)
    elif args.hostlist:
        with open(args.hostlist, 'r') as hostlist:
            hosts = hostlist.read().split()
        report = nmap_scan(hosts)
    else:
        print 'Please use the "-x [nmapoutput.xml]" option if you already have an nmap XML file \
or "-l [hostlist.txt]" option to run an nmap scan with a hostlist file.'
        sys.exit()

    main(report, args.workers)
