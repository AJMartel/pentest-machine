#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import re
import sys
import time
import signal
import argparse
import requests
import subprocess
import concurrent.futures as cf
from selenium import webdriver
from subprocess import Popen, STDOUT, PIPE
from multiprocessing import Process, Pool, Manager, Queue
from requests_futures.sessions import FuturesSession
from libnmap.process import NmapProcess
from libnmap.parser import NmapParser, NmapParserException
requests.packages.urllib3.disable_warnings()
# Debug
#from IPython import embed

def parse_args():
    # Create the arguments
    parser = argparse.ArgumentParser()
    parser.add_argument("-x", "--nmapxml", help="Nmap XML file to parse")
    parser.add_argument("-l", "--hostlist", help="Host list file")
    parser.add_argument("-w", "--workers", type=int, default=10, help="Number of parallel workers")
    parser.add_argument("--no-brute", help="SKip all bruteforce attacks", action="store_true")
    return parser.parse_args()

def make_output_dirs():
    '''
    Create output directories
    '''
    if not os.path.exists('output-by-host'):
        os.makedirs('output-by-host')
    if not os.path.exists('output-by-service'):
        os.makedirs('output-by-service')

def enqueue_cmds(queue, hosts, urls):
    '''
    Gather the commands to run
    '''
    hostnames = []
    cmds = []

    for host in report.hosts:
        ip = host.address
        if host.is_up():
            # type(host.hostnames) == list
            if len(host.hostnames) != 0:
                hostname = host.hostnames[0]

            # Each cmd = {service_str:[(cmd_string1, ip, service, bruteforce, slow_running)]}
            cmds += get_cmds_per_host(host, hostname, ip, urls, args)

    for c in cmds:
        queue.put(c)

def get_cmds_per_host(host, hostname, ip, urls, args):
    '''
    For each service type, add commands to run against it
    '''
    cmds = []

    if len(host.services) == 0:
        print '[-] No services detected'

    for s in host.services:
        port = str(s.port)

        # serv_cmds = {service_str:[(cmd_string1, ip, service, bruteforce, slow_running)]}
        serv_cmds = get_cmds_per_service(ip, port, urls)

        if 'open' == s.state:
            for serv in serv_cmds:
                # check if the service cmd is contained anywhere in the service name
                if re.search(serv, s.service):
                    for cmd in serv_cmds[serv]:
                        # Remove unnecessary cmds
                        cmd = filter_cmds(cmd)
                        cmds.append(cmd)

    # Remove bruteforce
    if args.no_brute and len(cmds) > 0:
        cmds = remove_brute(cmds)

    #Sort the commands so the fastest are at the front of the list
    # x[4] is boolean, True for slow running, False for fast running
    sorted_cmds = sorted(cmds, key=lambda x:x[4])
    cmds = sorted_cmds

    return cmds

def filter_cmds(cmd_data):
    '''
    Remove unnecessary cmds
    cmd_data[0] = command string
    '''
    # RPC
    # only do showmount if it's an NFS port
    if '/sbin/showmount' in cmd_data[0]:
        if port not in ['111', '2049']:
            return

    return cmd_data

def remove_brute(cmds):
    '''
    Remove bruteforce cmds from list
    '''
    for c in cmds:
        # c[4] is boolean for whether it's a brute cmd or not
        no_brute_cmds = [c for c in cmds if c[4] == False]

    return no_brute_cmds

def get_cmds_per_service(ip, port, urls):
    '''
    List of cmds to run on a per-service basis
    serv_cmds = {service_str:[(cmd_string, ip, service, bruteforce, slow_running)]}
    '''

    ip_port = '{0}:{1}'.format(ip, port)

    # Any better data structures?
    serv_cmds = {'ftp':[('patator ftp_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
-x ignore:egrep="failed" --max-retries 2 port={1}'.format(ip, port), ip_port, 'FTP', True, True)],

                 # Eventually add bruteforce against SMTP by first doing smtp_vrfy brute then using those SNs to attack
                 'smtp':[('sudo /usr/bin/nmap -sSV -Pn -n -pT{0} --script smtp-enum-users,smtp-open-relay {1}'.format(port, ip), ip_port, 'SMTP', False, False)],

                 'isakmp':[('sudo /usr/bin/ike-scan -M -A --id=none -Poutput-by-service/{0}-IKE-PSK.txt \
-Poutput-by-host/{0}-IKE-PSK.txt {0}'.format(ip), ip_port, 'ISAKMP', False, False)],

                 'postgre':[('patator postgresql_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
--max-retries 2'.format(ip), ip_port, 'Postgres', True, True)],

                 'mysql':[('patator mysql_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
--max-retries 2'.format(ip), ip_port, 'MYSQL', True, True)],

                 'telnet':[('patator telnet_login host={0} inputs="COMBO00\nCOMBO01" 0=wordlists/short-user-pass.list \
reset:fgrep!="Login incorrect", --max-retries 2'.format(ip), ip_port, 'Telnet', True, True)],

                 'ssh':[('patator ssh_login host={0} user=COMBO00 password=COMBO01 0=wordlists/long-user-pass.list \
-x ignore:egrep="failed." port={1} --max-retries 2'.format(ip, port), ip_port, 'SSH', True, True)],

                          # There's got to be a better way to do this
                 'snmp':[('patator snmp_login host={0} community=FILE0 0=wordlists/112-snmp.list'.format(ip), ip_port, 'SNMP', False, False)],
                         #('/usr/bin/snmpcheck -t {0}'.format(ip), ip_port, 'SNMP', False, False),
                         #('/usr/bin/snmpcheck -t {0} -c "private"'.format(ip), ip_port, 'SNMP', False, False),
                         #('/usr/bin/snmpcheck -t {0} -c "cisco"'.format(ip), ip_port, 'SNMP', False, False)],

                 'rpc':[('sudo /sbin/showmount -e {0}'.format(ip), ip_port, 'RPC', False, False)],

                 'smb':[('/usr/bin/enum4linux -a {0}'.format(ip), ip_port, 'SMB', False, False),
                        ('sudo /usr/bin/nmap -sSV -Pn -n -pT{0} --script smb-check-vulns,smb-enum-shares {1}'.format(port, ip), ip_port, 'SMB', False, False)],

                                                                                   # These are the only two rdp scripts
                 'ms-wbt-server':[('sudo /usr/bin/nmap -sSV -Pn -n -pT{0} --script rdp-enum-encryption,rdp-vuln-ms12-020 {1}'.format(port, ip), ip_port, 'RDP', False, False)],

                 'ntp':[('sudo /usr/bin/nmap -sSV -Pn -n -pU{0} --script ntp-monlist {1}'.format(port, ip), ip_port, 'NTP', False, False)],

                 'http|www|ssl':http_cmds(ip_port, urls)}

    return serv_cmds

def http_cmds(ip_port, urls):
    '''
    Form all the commands to run against HTTP services
    and add them to the Queue
    Runs: nikto, whatweb, screenshooter(), dirb
    '''
    cmds = []
    split = ip_port.split(':')
    ip = split[0]
    port = split[1]

    for ip_and_port in urls:
        # Check if the ip_port matches this single hosts's ip and port
        if ip_and_port == ip_port:
            for url in urls[ip_port]:

                # HTTP screenshots
                if not os.path.exists('output-by-service/HTTP-screenshots'):
                    os.makedirs('output-by-service/HTTP-screenshots')
                ss = 'screenshooter {0}'.format(url)
                cmds.append((ss, ip_port, 'HTTP', False, False))

                # Nikto
                nikto = '/usr/bin/nikto -h {0}'.format(url)
                cmds.append((nikto, ip_port, 'HTTP', False, True))

                # WhatWeb
                whatweb = '/usr/bin/whatweb {0}'.format(url)
                cmds.append((whatweb, ip_port, 'HTTP', False, False))

                # Directory bruteforcing
                dirb = '/usr/bin/dirb {0} {1}'.format(url, 'wordlists/dirs-1800.list')
                cmds.append((dirb, ip_port, 'HTTP', True, True))

    return cmds

def get_urls(report):
    '''
    Create, then asynchronously test all the valid URLs based on http/https and ip/hostname
    '''

    # Create all potential URLs from the IP and hostname
    potential_urls = get_potential_urls(report)

    # Start asynchronous requests to the potential URLs
    resps = resps_from_urls(potential_urls)

    # Get the results from the requests to the potential URLs
    urls = get_working_urls(resps)

    return urls

def get_working_urls(resps):
    '''
    Test each potential URL for a valid resp
    '''
    urls = {}

    print '\n[*] Asynchronously gathering valid URLs...'
    for resp in cf.as_completed(resps):
        try:
            if resp.result().status_code in [200, 401]:
                url, ip_port = resps[resp]
                print '[+]   Successful response: {0}'.format(url)
                if ip_port in urls:
                    urls[ip_port] += [url]
                else:
                    urls[ip_port] = [url]
        except Exception as e:
            pass

    print ''
    return urls

def get_potential_urls(report):
    '''
    Print all the hosts and services per host
    Create all potential URL combinations from the nmap IP/hostname
        http://ip
        http://hostname
        https://ip
        https://hostname
    '''
    potential_urls = {}

    for host in report.hosts:
        ip = host.address
        if host.is_up():
            hostname = None
            if len(host.hostnames) != 0:
                hostname = host.hostnames[0]
                print '\n[*] Host: {0}  Hostname: {1}'.format(ip, hostname)
            else:
                print '\n[+] Host: {0}'.format(ip)
            for s in host.services:
                port = str(s.port)
                print '[*]   {0}/{1} {2} {3}'.format(port, s.protocol, s.state, s.service)
                ip_port = '{0}:{1}'.format(ip, port)
                if re.search('http|www|ssl', s.service):
                    # Create the potential URLs
                    host_urls = make_urls(ip, port, hostname)
                    if host_urls:
                        potential_urls[ip_port] = host_urls

    return potential_urls

def resps_from_urls(potential_urls):
    '''
    Gather valid responses from the list of potential urls
    '''
    resps = {}
    session = FuturesSession(max_workers=25)

    for ip_port in potential_urls:
        host_resps = []
        for url in potential_urls[ip_port]:
            resp = session.get(url, timeout=20, verify=False)
            host_resps.append(resp)
            resps[resp] = (url, ip_port)

    return resps

def screenshooter(ip, url):
    '''
    Open a phantomjs browser and take a screenshot
    '''

    output = ''

    try:
        browser = webdriver.PhantomJS(service_args=['--ignore-ssl-errors=true','--ssl-protocol=tlsv1'], executable_path="phantomjs")
    except WebDriverException:
        output += '[-] PhantomJS failed, are you sure its installed and in your $PATH?\n'
        return output

    output += '[*] Taking screenshot of {0}\n'.format(url)
    ss_name = url.split('://')[1].replace(':', '-')
    browser.set_window_size(1024, 768)
    browser.set_page_load_timeout(60)

    try:
        browser.get(url)

        # Selenium makes the page source equal to this when it fails to connect
        if '<html><head></head><body></body></html>' == browser.page_source:
            output += '[-] Failed to fetch the page\n'
            return output

        fname = 'output-by-service/HTTP-screenshots/{0}.png'.format(ss_name)
        browser.save_screenshot(fname)
    except Exception as e:
        output += '[-] Failed: {0}\n'.format(str(e))
        return output

    output += '[+] Saved screenshot {0}.png'.format(ss_name)
    browser.quit()

    return output

def make_urls(ip, port, hostname):
    '''
    Create all potential URLs, http://hostname, http://ip, https://hostname, https://ip
    '''
    urls = []

    if port == '443':
        if hostname:
            urls.append('https://{0}:{1}'.format(hostname, port))
        urls.append('https://{0}:{1}'.format(ip, port))
        return urls
    else:
        if hostname:
            urls.append('http://{0}:{1}'.format(hostname, port))
            urls.append('https://{0}:{1}'.format(hostname, port))
        urls.append('http://{0}:{1}'.format(ip, port))
        urls.append('https://{0}:{1}'.format(ip, port))
        return urls

def worker(lock, queue, proc_monitor):
    '''
    Multiprocessing worker that actually runs the commands
    '''
    signal.signal(signal.SIGINT, signal.SIG_IGN)
    pid = os.getpid()

    #while queue.qsize() > 0:
    while 1:
        waiting_for_item = True

        # Necessary to catching CTRL-C
        try:
            # This has to wait for write_output() and causes IOError sometimes on CTRL-C
            proc_monitor[pid] = waiting_for_item
            # This causes EOFError on CTRL-C
            cmd_data = queue.get()
        except (EOFError, IOError):
            return

        # Tells the shared dict proc_monitor that we are performing actions
        # based on a queue object so don't finish the script yet
        proc_monitor[pid] = False
        cmd = cmd_data[0]
        cmd_list = cmd.split()
        ip_port = cmd_data[1]
        split = ip_port.split(':')
        ip = split[0]
        port = split[1]
        service = cmd_data[2]

        out = run_cmd(cmd_list, cmd, ip)
        out = adjust_output(cmd, out)

        # On Ctrl-C will throw IOError if it came while writing
        try:
            if out:
                write_output(lock, cmd, ip, service, out)
        except IOError:
            pass

        # Add new cmds
        add_new_cmds(queue, cmd_list, ip_port, out)


############################# ADD NEW CMDS #####################################################
def add_new_cmds(queue, cmd_list, ip_port, out):
    '''
    Based the output of one of the originally run cmds, add new cmds
    to the queue for the workers to process
    '''
    new_cmds = {'/usr/bin/whatweb':add_wpscan(out, ip_port, queue, cmd_list),
               'snmp_login':add_snmpcheck(out, ip_port, queue, cmd_list)}

    for cmd_snippet in new_cmds:
        if cmd_snippet in cmd_list:
            new_cmds[cmd_snippet]

def add_snmpcheck(out, ip_port, queue, cmd_list):
    '''
    Add snmpcheck to gather info from valid SNMP logins
    '''
    split = ip_port.split(':')
    ip = split[0]

    if 'snmp_login' in cmd_list:
        out_lines = out.splitlines()
        for l in out_lines:
            # 0-0 is the code and is only found on lines of output referring to a brute attempt
            if '0-0' in l:
                if 'No SNMP response received' not in l:
                    split_line = l.split()
                    comm_str = split_line[7]
                    snmpcheck = 'snmpcheck -t {0} -c {1}'.format(ip, comm_str)
                    queue.put((snmpcheck, ip_port, 'SNMP', False, False))

def add_wpscan(out, ip_port, queue, cmd_list):
    '''
    Add WPScan to queue if "wordpress" is in whatweb output
    '''
    if 'wordpress' in out.lower():
        url = cmd_list[1]
        wp = 'sudo /usr/bin/wpscan {0}'.format(url)
        queue.put((wp, ip_port, 'HTTP', False, False))
################################################################################################


def run_cmd(cmd_list, cmd, ip):
    '''
    Run either the OS command or call a function based on cmd_data
    '''
    out = None

    # Run python functions, come in as "<functionname> <args>"
    if 'screenshooter' == cmd_list[0]:
        print '[*] Running command: {0}'.format(cmd)
        url = cmd.split()[1]
        out = screenshooter(ip, url)

    # Run OS cmds
    else:
        print '[*] Running command: {0}'.format(cmd)
        proc = Popen(cmd_list, stdout=PIPE, stderr=STDOUT)
        out = proc.communicate()[0].strip()

    return out

def write_output(lock, cmd, ip, service, out):
    '''
    Write each cmd's output to a file named by the IP and a file named by the service type
    '''
    with lock:
        msg = '\n[+] OUTPUT: {0}\n{1}'.format(cmd, out)
        print msg

        with open('output-by-host/{0}.txt'.format(ip), 'a+') as f:
            f.write(msg)
        with open('output-by-service/{0}.txt'.format(service), 'a+') as f:
            f.write(msg)

def adjust_output(cmd, out):
    '''
    Remove output from cmds with too much of it and remove errors from some cmds' output
    '''

    skip_output = ['/usr/bin/dirb']

    # Ignore cmds with too much or unprintable output
    for i in skip_output:
        if i == cmd:
            return

    # Skip certain output lines
    adjusted_out = ''
    for l in out.split('\n'):

        # Skip error line in whatweb
        if 'iconv will be deprecated in the future' not in l:
            adjusted_out += l + '\n'

    # Escape colors like whatweb has
    ansi_escape = re.compile(r'\x1b[^m]*m')
    out = ansi_escape.sub('', adjusted_out)

    return out

def nmap_scan(hosts):
    '''
    Do Nmap scan
    '''
    # -sV is included by default in NmapProcess nmap cmd
    # To add more:  options = '-T4 -sU -p-'
    #                 hosts = ['192.168.0.1', '192.168.0.2']
    #nmap_args = '-T4 -sV -sS -pU:161,137,139'# -sS -sU --top-ports'
    nmap_args = '-T4 -sS -sV --max-rtt-timeout 150ms --max-retries 3'
    print '[*] Running: nmap {0} -iL <hostlist>'.format(nmap_args)
    nmap_proc = NmapProcess(targets=hosts, options=nmap_args)
    #rc = nmap_proc.sudo_run()
    rc = nmap_proc.sudo_run_background()
    while nmap_proc.is_running():
        print("[*] Nmap progress: {1}%".format(nmap_proc.etc, nmap_proc.progress))
        time.sleep(2)

    xml = nmap_proc.stdout

    try:
        report = NmapParser.parse(nmap_proc.stdout)
    except NmapParserException as e:
        print 'Exception raised while parsing scan: {0}'.format(e.msg)
        sys.exit()

    return report

def pool_monitor(lock, pool, proc_monitor):
    '''
    Watch the proc_monitor variable which is {pid:waiting_for_item} and when all pids
    are waiting for an item in the queue and not performing an action, then terminate
    the process pool and join it
    '''
    signal.signal(signal.SIGINT, signal.SIG_IGN)
    while 1:
        time.sleep(1)

        procs_waiting = []
        # Can't iterate over DictProxy which is what Manager().dict() is so gotta do this
        pids = iter(proc_monitor.keys())
        for p in pids:
            procs_waiting.append(proc_monitor[p])

        if all(procs_waiting):
            print procs_waiting
            pool.terminate()
            pool.join()
            return

def main(report, num_workers):
    '''
    Run through the hosts' available services appending their respective commands
    to a list, then have x number of workers run through those commands
    '''
    args = parse_args()
    # Can't just use multiprocessing.Lock() because you can't share locks between pool-created Processes
    m = Manager()
    lock = m.Lock()
    proc_monitor = m.dict()
    # Regular Queue() gets pickled and unpickled by each worker which means its copied so it can't be shareed between Procs
    queue = m.Queue()

    # Create output directories
    make_output_dirs()

    # Check web services for valid URLs
    urls = get_urls(report)

    # Enqueue all the cmds based on the services detected
    enqueue_cmds(queue, report.hosts, urls)

    # Kick off the workers in the Pool
    pool = Pool(num_workers, worker, (lock, queue, proc_monitor))

    # Catching CTRL-C inside pool.async_apply is not straightforward
    # Pool initialized with init_worker which catches CTRL-C then ignores it which
    # forces it to move into the main() func which is then caught here accurately
    def signal_handler(signal, frame):
        print '\n[-] Killing unfinished processes...'
        if os.path.isfile('ghostdriver.log'):
            os.remove('ghostdriver.log')
        pool.terminate()
        pool.join()
        sys.exit()
    signal.signal(signal.SIGINT, signal_handler)

    # Every second check if all the processes are waiting on the queue which would
    # mean all cmds are done and all are just infinitely waiting for a new task
    while 1:
        time.sleep(1)

        procs_waiting = []
        # Can't iterate over DictProxy with `for key in DictProxy`
        # which is what Manager().dict() is so gotta do this
        pids = iter(proc_monitor.keys())
        for p in pids:
            procs_waiting.append(proc_monitor[p])

        # If all procs are just waiting, then we're done
        if all(procs_waiting):
            pool.terminate()
            pool.join()
            return

if __name__ == "__main__":

    args = parse_args()

    if os.geteuid():
        exit('[-] Please run as root')

    if args.nmapxml:
        report = NmapParser.parse_fromfile(args.nmapxml)
    elif args.hostlist:
        with open(args.hostlist, 'r') as hostlist:
            hosts = hostlist.read().split()
        report = nmap_scan(hosts)
    else:
        print 'Please use the "-x [nmapoutput.xml]" option if you already have an nmap XML file \
or "-l [hostlist.txt]" option to run an nmap scan with a hostlist file.'
        sys.exit()

    main(report, args.workers)
